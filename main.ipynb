{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "For Google Colab Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import yaml\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get(video_path):\n",
    "    # Use cv2 to read the video at fps=30\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Check if the video was successfully opened\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames, {\n",
    "        \"fps\": fps,\n",
    "        \"width\": frame.shape[1],\n",
    "        \"height\": frame.shape[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(frames, fps_old, fps_new):\n",
    "    # Load the image from the URL\n",
    "    ratio = fps_old // fps_new\n",
    "    frames = frames[::ratio]\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(frames, pipeline):\n",
    "    results = []\n",
    "    for frame in frames:\n",
    "        results.append(pipeline(frame))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_save(results, config, weight, height):\n",
    "    # Connect the segments\n",
    "    masks = [results[i]['mask'] for i in range(len(results))]\n",
    "    # Make the frames of the masks into video\n",
    "    video = cv2.VideoWriter(config['output']['output_path'], cv2.VideoWriter_fourcc(*'mp4v'), config['output']['fps'], (weight, height))\n",
    "    for image in results:\n",
    "        video.write(image)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "    print(\"Video saved at\", config['output']['output_path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    config = yaml.safe_load(open(\"config.yaml\"))\n",
    "    output_dir = os.path.dirname(config['output']['output_path'])\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    video_name = os.path.basename(config['video_path'])\n",
    "    config['output']['output_path'] = os.path.join(output_dir, video_name)\n",
    "\n",
    "    # as of now, only \"nvidia/segformer-b1-finetuned-cityscapes-1024-1024\" is supported for this usage\n",
    "    semantic_segmentation = pipeline(\"image-segmentation\", config['model'])\n",
    "    frames, etc = get(config[\"video_path\"])\n",
    "    frames = preprocess(frames, etc['fps'], config['output']['fps'])\n",
    "    with torch.no_grad():\n",
    "        segments = segment(frames, semantic_segmentation)\n",
    "    connect_save(segments, config, etc['width'], etc['height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
